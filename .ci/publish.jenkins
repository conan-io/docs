#!groovyâ€‹


node('Linux') {

try {
        // To generate the docs locally run the following, better redirect sources_folder and gh_pages_out
        // to folders outside this repo. Add --branches arguments for the branches you want to regenerate

        // python .ci/scripts/prepare_sources.py --sources-folder=../cloned_sources --branches=release/2.0 --branches=master

        // python .ci/scripts/generate_documentation.py --sources-folder=../cloned_sources --branch=$release/2.0 --with-pdf
        // python .ci/scripts/generate_documentation.py --sources-folder=../cloned_sources --branch=master --with-pdf

        // python .ci/scripts/prepare_gh_pages.py --sources-folder=../cloned_sources --gh-pages-folder=../gh_pages_out

        // Then go to ../gh_pages_out and test the docs using a local server like: 'python -m http.server 8000'
        // and open: 'http://localhost:8000/2.0/index.html'

        String output_contents = 'output_contents'
        String sources_folder = 'sources_folder'
        String gh_pages_out = 'gh_pages_out'

        assert params.branches, 'Provide a list of branches to publish, separated by ","'

        List branches = params.branches.split(',')
        echo "Generating docs for ${branches}"

        checkout scm
        def image = null
        stage('Build docker image') {
            // Build the docker image using the same commit as the current 'publish.jenkins' file
            image = docker.build('conan-docs', '-f .ci/Dockerfile .')  // It should cache the image
        }

        stage('Prepare sources as worktrees') {        
            String branch_argument = ""
            for (branch in branches) {
                branch_argument = branch_argument + " --branches=${branch}"
            } 
            // clone sources to generate docs
            sh(script: "python .ci/scripts/prepare_sources.py --sources-folder=${sources_folder} ${branch_argument}")
        }

        // we have to divide the parallel blocks because if we have to generate all branches documentation
        // it will fail

        def number_of_parallel_blocks = (branches.size()<10) ? 1 : 2
        def branches_blocks = branches.collate(branches.size().intdiv(number_of_parallel_blocks))

        for (branches_block in branches_blocks) {
            Map parallelJobs = [:]
            println("New block ${branches_block}")
            branches_block.each { branch ->
                parallelJobs[branch] = {
                    echo "Run parallel job for ${branch}"
                    image.inside {
                        sh(script: "python .ci/scripts/generate_documentation.py --sources-folder=${sources_folder} --branch=${branch} --with-pdf")
                    }
                }
            }
            stage('Generate docs parallel block') {
                parallelJobs.failFast = true
                parallel parallelJobs
            }
        }

        stage('Prepare gh-pages') {
            sh(script: "python .ci/scripts/prepare_gh_pages.py --sources-folder=${sources_folder} --gh-pages-folder=${gh_pages_out}")
        }


        stage('Archive generated folder') {
            archiveArtifacts artifacts: "${gh_pages_out}/**/*.*"
            echo "Inspect generated webpage at ${BUILD_URL}artifact/${gh_pages_out}/index.html"
        }

        if (params.publish) {
            stage('Publish to gh-pages') {
                dir(gh_pages_out) {
                    sh 'git add .'
                    sh 'git config user.email "conanci@jfrog.com"'
                    sh 'git config user.name "ConanCI bot"'
                    sh "git commit -m \"Automatic deploy (build number ${BUILD_NUMBER})\""
                    withCredentials([usernamePassword(credentialsId: 'conanci-gh-token', usernameVariable: 'GH_USER', passwordVariable: 'GH_PASS')]) {
                        sh "git remote add origin-pages https://$GH_USER:$GH_PASS@github.com/conan-io/docs.git"
                        sh 'git push origin-pages gh-pages'
                    }
                }
            }
        }
    }
    finally {
        cleanWs(cleanWhenAborted: true, cleanWhenFailure: true, cleanWhenNotBuilt: true,
                cleanWhenSuccess: true, cleanWhenUnstable: true, disableDeferredWipeout: true, deleteDirs: true,
                notFailBuild: true)
    }
}
